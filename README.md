# Предиктивный анализ оттока клиентов
![churn customer](https://static9.depositphotos.com/1202020/1221/i/600/depositphotos_12212262-stock-photo-marketing-campaign-business-success.jpg)
## Описание проекта

**ЦЕЛЬ ПРОЕКТА:**

Провести исследование и построить модель **прогнозирования ухода клиентов** из банка, что позволит `сократить затраты` на привлечение новых клиентов.

В нашем распоряжении обезличенные данные пользователей и история `использования услуг`.


KPI успеха проекта - `F1-score >= 0.59` 

Это классический таргет для бизнес-задач. Будет отлично, если более **детальный анализ** позволит получить результаты с еще большей точностью.

---

**ЛИЧНАЯ ЦЕЛЬ:**

В прошлом проекте с рекомендацией тарифов мы успели заметить проблему **дисбаланса классов**, а после обучения моделей обнаружили, что `accuracy` была неподходящей **метрикой**.

Наша логистическая регрессия показывала нулевой precision и recall для 1-го класса:

- Теперь мы вооружены  методами для **борьбы с неравными классами** и сможем протестировать их работу на практике. 


- Научимся правильно интерпретировать `Recall`, `Precision`, `F1_score`, `ROC_AUC` и `PR-кривые`. Посмотрим, действительно ли они могут искажать результаты на imbalanced классах, как об этом пишут.

Также испытаем новые инструменты:

1. Попробуем "на лету" строить **пайплайны** из данных с помощью `Pandas`  и использовать метод `make_pipeline` для трансформеров.


2. Проведем эксперименты подбора базовых гиперпараметров c визуализацией `learning_curve` и `validation_curve`


3. Посмотрим, как дополнительные **методы корреляции** (кроме Пирсона) могут помочь в анализе данных и построении качественной модели.


[Посмотреть проект](Customer_churn_prediction_v1.ipynb)

## Новые навыки

<div class="alert alert-success">
<br> ✔️ Борьба с дисбалансом классов (custom функции для Оversampling & Undersampling</br>
<br> ✔️ Числовые и категориальные признаки </br> ✔️ Корреляции Спирмена и Пирсона </br>
<br> ✔️ Анализ относительных частот</br> ✔️ Использование трэшхолдов в классификации </br>
<br> ✔️ ROC AUC ✔️ F1-score ✔️ Precision ✔️ Recall</br>
<br> ✔️ Пайплайны обработки данных</br>
</div>

## Этапы исследования

1. Исследовали различные **факторы ухода клиентов**:

     - Проверили `валидность всех данных`, которые будут использоваться предсказательной моделью 
     - Изучили влияние различных признаков, основываясь на **корреляции** и **частотном анализе**.
     - **Увеличили корреляцию**, создав категории для численных признаков c помощью `Target Encoding`
     - Выбрали те признаки, которые **слабо влияют на уход** клиентов

3. Построили базовые модели-классификаторы на базе **3-х алгоритмов**:

    - LogisticRegression
    - DecisionTree
    - RandomForest

4. Провели эксперименты для борьбы с **дисбалансом классов**:

    - Параметр `class_weight=balanced`
    - Undersampling 
    - Oversampling
    
5. Выполнили поиск **лучшего трэшхолда** для максимизации `f1-score`

6. Визуализировали качество предсказаний с помощью **Precision-Recall** и **ROC-AUC** кривых.

7. Выявили сегмент **Заказчиков из Германии**, на которых базируется точность построенной модели

## Результат проекта

Результат проекта  - две модели на базе алгоритмов **Решающего Дерева** и **Случайного Леса**
для предсказания `Churn Customer`.

====> RandomForest (Случайный Лес, 60 деревьев, max_depth=7)

Результаты на валидационной и тестовой выборках:

- Порог = 0.50 | Точность = 0.512, Полнота = 0.718, F1_score = 0.598 | roc_auc = 0.770

- Порог = 0.50 | Точность = 0.510, Полнота = 0.742, F1_score = 0.604 | roc_auc = 0.785

====> DecisionTree (Решающее Дерево, max_depth=8)

Результаты на валидационной и тестовой выборках:

- Порог = 0.40 | Точность = 0.502, Полнота = 0.712, F1_score = 0.589 | roc_auc = 0.764

- Порог = 0.40 | Точность = 0.508, Полнота = 0.705, F1_score = 0.591 | roc_auc = 0.771

Даже на несложных моделях мы построили решение, которое удовлетворяют **целевому KPI**.

Возможности для развития проекта - использовать `CatBoost Classificator` для повышения точности предскаазний.


## Исходные данные


```python
import pandas as pd

df = pd.read_csv("https://code.s3.yandex.net/datasets/Churn.csv")
display(df.iloc[:, :6].head(3))
df.iloc[:, 6:].head(3)
```


<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>RowNumber</th>
      <th>CustomerId</th>
      <th>Surname</th>
      <th>CreditScore</th>
      <th>Geography</th>
      <th>Gender</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>15634602</td>
      <td>Hargrave</td>
      <td>619</td>
      <td>France</td>
      <td>Female</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>15647311</td>
      <td>Hill</td>
      <td>608</td>
      <td>Spain</td>
      <td>Female</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>15619304</td>
      <td>Onio</td>
      <td>502</td>
      <td>France</td>
      <td>Female</td>
    </tr>
  </tbody>
</table>
</div>





<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Age</th>
      <th>Tenure</th>
      <th>Balance</th>
      <th>NumOfProducts</th>
      <th>HasCrCard</th>
      <th>IsActiveMember</th>
      <th>EstimatedSalary</th>
      <th>Exited</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>42</td>
      <td>2.0</td>
      <td>0.00</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>101348.88</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>41</td>
      <td>1.0</td>
      <td>83807.86</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>112542.58</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>42</td>
      <td>8.0</td>
      <td>159660.80</td>
      <td>3</td>
      <td>1</td>
      <td>0</td>
      <td>113931.57</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>


